{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando pacotes necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='keras')\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar o modelo de rede neural\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando a seleção de Dados por k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o arquivo 'dados.csv' no dataframe\n",
    "df_kfold = pd.read_csv('df_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis objetivo\n",
    "X = df_kfold.drop('CLASSE', axis=1)\n",
    "y = df_kfold['CLASSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo o número de folds\n",
    "\n",
    "num_folds = 7\n",
    "sub_num_folds = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar o k-Fold Principal\n",
    "\n",
    "kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir os Dados para o k-fold teste\n",
    "\n",
    "fold_indices = list(kf.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre cada fold principal\n",
    "for fold, (train_index, test_index) in enumerate(fold_indices):\n",
    "    # Dados de treino e teste para o fold principal\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Aplicar o sub-k-fold para treino e validação\n",
    "    sub_kf = StratifiedKFold(n_splits=sub_num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Armazenar os índices dos folds secundários\n",
    "    sub_fold_indices = list(sub_kf.split(X_train, y_train))\n",
    "\n",
    "    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_fold_indices):\n",
    "        # Dados de treino e validação para o sub-k-fold\n",
    "        X_sub_train, X_sub_val = X_train.iloc[sub_train_index], X_train.iloc[sub_val_index]\n",
    "        y_sub_train, y_sub_val = y_train.iloc[sub_train_index], y_train.iloc[sub_val_index]\n",
    "\n",
    "        # Aqui você pode treinar e validar seu modelo\n",
    "        # Exemplo: print(f'Fold {fold + 1}, Sub-Fold {sub_fold + 1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando disposição das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import pandas as pd\n",
    "\n",
    "# # Exemplo de dataframe com rótulos (alvo)\n",
    "# y = pd.Series(y)  # Supondo que seus rótulos estejam em um array ou lista chamada 'y'\n",
    "\n",
    "# # Inicializar o StratifiedKFold\n",
    "# kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# # Iterar pelos folds principais\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     # Contagem das classes no treino e teste\n",
    "#     train_counts = Counter(y_train)\n",
    "#     test_counts = Counter(y_test)\n",
    "    \n",
    "#     # print(f\"Fold {fold + 1}\")\n",
    "#     # print(f\"Distribuição no treino: {train_counts}\")\n",
    "#     # print(f\"Distribuição no teste: {test_counts}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui é só pra contar e ver a proporção dos Folds e Subfolds\n",
    "\n",
    "# Suponha que X seja um DataFrame e y seja uma Series\n",
    "# Se X é um DataFrame e y é uma Series\n",
    "kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterar pelos folds principais\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Contagem das classes no treino e teste\n",
    "    train_counts = Counter(y_train)\n",
    "    test_counts = Counter(y_test)\n",
    "    \n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(f\"Distribuição no treino: {train_counts}\")\n",
    "    print(f\"Distribuição no teste: {test_counts}\\n\")\n",
    "\n",
    "    # Subdividir o treino em subfolds\n",
    "    sub_kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "    \n",
    "    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_kfold.split(X_train, y_train)):\n",
    "        y_sub_train = y_train.iloc[sub_train_index]\n",
    "        y_sub_val = y_train.iloc[sub_val_index]\n",
    "        \n",
    "        # Contagem das classes nos subfolds\n",
    "        sub_train_counts = Counter(y_sub_train)\n",
    "        sub_val_counts = Counter(y_sub_val)\n",
    "        \n",
    "        print(f\"  Subfold {sub_fold + 1}\")\n",
    "        print(f\"  Distribuição no treino: {sub_train_counts}\")\n",
    "        print(f\"  Distribuição na validação: {sub_val_counts}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando as redes neurais no k-fold do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar as métricas de avaliação\n",
    "validation_reports = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"best_model.keras\"  # Local para salvar o melhor modelo\n",
    "\n",
    "# Configurar o callback para salvar o melhor modelo com base na métrica de validação\n",
    "checkpoint = ModelCheckpoint(best_model_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Variável para armazenar o melhor desempenho\n",
    "best_val_accuracy = 0\n",
    "best_fold = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar uma lista para armazenar a precisão ponderada de cada fold\n",
    "fold_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir precisões ponderadas de cada fold\n",
    "for accuracy in fold_accuracies:\n",
    "    print(f\"Fold {accuracy['fold']}, Sub-Fold {accuracy['sub_fold']}: Acurácia de Teste = {accuracy['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar os rótulos para garantir que estejam no intervalo esperado\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D842481B20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D842481B20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "# Armazenar as precisões por classe para cada sub-fold\n",
    "sub_fold_precisions = []\n",
    "\n",
    "# Exibir a precisão de cada classe\n",
    "for fold, (train_index, test_index) in enumerate(fold_indices):\n",
    "    # Dados de treino e teste para o fold principal\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Aplicar Sub-K-Fold para treino e validação\n",
    "    sub_fold_indices = list(sub_kf.split(X_train, y_train))\n",
    "    \n",
    "    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_fold_indices):\n",
    "        # Dados de treino e validação para o sub-k-fold\n",
    "        X_sub_train, X_sub_val = X_train.iloc[sub_train_index], X_train.iloc[sub_val_index]\n",
    "        y_sub_train, y_sub_val = y_train[sub_train_index], y_train[sub_val_index]\n",
    "        \n",
    "        # Criar o modelo\n",
    "        num_classes = len(label_encoder.classes_)\n",
    "        model = create_model(X.shape[1], num_classes)\n",
    "        \n",
    "        # Treinar o modelo e salvar o histórico\n",
    "        history = model.fit(\n",
    "            X_sub_train, y_sub_train, \n",
    "            epochs=100, batch_size=32, \n",
    "            verbose=0, validation_data=(X_sub_val, y_sub_val),\n",
    "            callbacks=[checkpoint]\n",
    "        )\n",
    "\n",
    "        # Avaliar no conjunto de teste\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "        # Calcular acurácia de teste\n",
    "        test_accuracy = np.mean(y_test_pred_classes == y_test)\n",
    "\n",
    "        # Atualizar o melhor modelo se este fold for melhor\n",
    "        if test_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = test_accuracy\n",
    "            best_fold = (fold, sub_fold)\n",
    "        \n",
    "        # Calcular a matriz de confusão\n",
    "        cm = confusion_matrix(y_test, y_test_pred_classes, labels=np.arange(num_classes))\n",
    "        \n",
    "        # Calcular a precisão de cada classe\n",
    "        class_precisions = precision_score(y_test, y_test_pred_classes, average=None)\n",
    "        \n",
    "        # Armazenar a precisão de cada classe para o sub-fold\n",
    "        sub_fold_precisions.append({\n",
    "            'fold': fold,\n",
    "            'sub_fold': sub_fold,\n",
    "            'precisions': class_precisions\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.2000\n",
      "  Precisão da Classe 1: 0.6250\n",
      "  Precisão da Classe 2: 0.4500\n",
      "  Precisão da Classe 3: 0.4222\n",
      "  Precisão da Classe 4: 0.5897\n",
      "  Precisão da Classe 5: 0.7000\n",
      "Fold 0, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.1667\n",
      "  Precisão da Classe 2: 0.4750\n",
      "  Precisão da Classe 3: 0.4681\n",
      "  Precisão da Classe 4: 0.6250\n",
      "  Precisão da Classe 5: 0.8000\n",
      "Fold 0, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.5714\n",
      "  Precisão da Classe 2: 0.3684\n",
      "  Precisão da Classe 3: 0.4130\n",
      "  Precisão da Classe 4: 0.5897\n",
      "  Precisão da Classe 5: 0.6522\n",
      "Fold 0, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.5714\n",
      "  Precisão da Classe 2: 0.5484\n",
      "  Precisão da Classe 3: 0.4717\n",
      "  Precisão da Classe 4: 0.6216\n",
      "  Precisão da Classe 5: 0.7391\n",
      "Fold 0, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.2000\n",
      "  Precisão da Classe 1: 0.7143\n",
      "  Precisão da Classe 2: 0.5000\n",
      "  Precisão da Classe 3: 0.4694\n",
      "  Precisão da Classe 4: 0.6053\n",
      "  Precisão da Classe 5: 0.7273\n",
      "Fold 0, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.4000\n",
      "  Precisão da Classe 1: 0.6000\n",
      "  Precisão da Classe 2: 0.4595\n",
      "  Precisão da Classe 3: 0.4528\n",
      "  Precisão da Classe 4: 0.6053\n",
      "  Precisão da Classe 5: 0.7895\n",
      "Fold 0, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.4286\n",
      "  Precisão da Classe 1: 0.2000\n",
      "  Precisão da Classe 2: 0.4412\n",
      "  Precisão da Classe 3: 0.4118\n",
      "  Precisão da Classe 4: 0.5833\n",
      "  Precisão da Classe 5: 0.7083\n",
      "Fold 1, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.5000\n",
      "  Precisão da Classe 1: 0.2500\n",
      "  Precisão da Classe 2: 0.3636\n",
      "  Precisão da Classe 3: 0.3421\n",
      "  Precisão da Classe 4: 0.4884\n",
      "  Precisão da Classe 5: 0.8182\n",
      "Fold 1, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.2000\n",
      "  Precisão da Classe 1: 0.2500\n",
      "  Precisão da Classe 2: 0.4211\n",
      "  Precisão da Classe 3: 0.3750\n",
      "  Precisão da Classe 4: 0.4667\n",
      "  Precisão da Classe 5: 0.6667\n",
      "Fold 1, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.6667\n",
      "  Precisão da Classe 1: 0.2222\n",
      "  Precisão da Classe 2: 0.4286\n",
      "  Precisão da Classe 3: 0.3333\n",
      "  Precisão da Classe 4: 0.4750\n",
      "  Precisão da Classe 5: 0.6000\n",
      "Fold 1, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 1.0000\n",
      "  Precisão da Classe 1: 0.2500\n",
      "  Precisão da Classe 2: 0.4510\n",
      "  Precisão da Classe 3: 0.4211\n",
      "  Precisão da Classe 4: 0.4750\n",
      "  Precisão da Classe 5: 0.6957\n",
      "Fold 1, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.4348\n",
      "  Precisão da Classe 3: 0.3871\n",
      "  Precisão da Classe 4: 0.5106\n",
      "  Precisão da Classe 5: 0.8421\n",
      "Fold 1, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.4286\n",
      "  Precisão da Classe 2: 0.4878\n",
      "  Precisão da Classe 3: 0.4211\n",
      "  Precisão da Classe 4: 0.5111\n",
      "  Precisão da Classe 5: 0.6957\n",
      "Fold 1, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.3953\n",
      "  Precisão da Classe 3: 0.4054\n",
      "  Precisão da Classe 4: 0.5106\n",
      "  Precisão da Classe 5: 0.7500\n",
      "Fold 2, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.1250\n",
      "  Precisão da Classe 2: 0.5789\n",
      "  Precisão da Classe 3: 0.4390\n",
      "  Precisão da Classe 4: 0.5484\n",
      "  Precisão da Classe 5: 0.6286\n",
      "Fold 2, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.5000\n",
      "  Precisão da Classe 3: 0.5116\n",
      "  Precisão da Classe 4: 0.5366\n",
      "  Precisão da Classe 5: 0.7500\n",
      "Fold 2, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.0769\n",
      "  Precisão da Classe 2: 0.5758\n",
      "  Precisão da Classe 3: 0.5250\n",
      "  Precisão da Classe 4: 0.5676\n",
      "  Precisão da Classe 5: 0.6667\n",
      "Fold 2, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.2000\n",
      "  Precisão da Classe 1: 0.1111\n",
      "  Precisão da Classe 2: 0.5405\n",
      "  Precisão da Classe 3: 0.5227\n",
      "  Precisão da Classe 4: 0.6333\n",
      "  Precisão da Classe 5: 0.6875\n",
      "Fold 2, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.1250\n",
      "  Precisão da Classe 1: 0.0000\n",
      "  Precisão da Classe 2: 0.5172\n",
      "  Precisão da Classe 3: 0.5000\n",
      "  Precisão da Classe 4: 0.5294\n",
      "  Precisão da Classe 5: 0.6552\n",
      "Fold 2, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.1429\n",
      "  Precisão da Classe 2: 0.4524\n",
      "  Precisão da Classe 3: 0.5135\n",
      "  Precisão da Classe 4: 0.5750\n",
      "  Precisão da Classe 5: 0.6897\n",
      "Fold 2, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.5000\n",
      "  Precisão da Classe 1: 0.1000\n",
      "  Precisão da Classe 2: 0.5833\n",
      "  Precisão da Classe 3: 0.5000\n",
      "  Precisão da Classe 4: 0.5714\n",
      "  Precisão da Classe 5: 0.7143\n",
      "Fold 3, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.4182\n",
      "  Precisão da Classe 3: 0.4872\n",
      "  Precisão da Classe 4: 0.7857\n",
      "  Precisão da Classe 5: 0.7931\n",
      "Fold 3, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 1.0000\n",
      "  Precisão da Classe 1: 0.4286\n",
      "  Precisão da Classe 2: 0.5306\n",
      "  Precisão da Classe 3: 0.4524\n",
      "  Precisão da Classe 4: 0.6897\n",
      "  Precisão da Classe 5: 0.7586\n",
      "Fold 3, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.3750\n",
      "  Precisão da Classe 2: 0.4565\n",
      "  Precisão da Classe 3: 0.4750\n",
      "  Precisão da Classe 4: 0.6429\n",
      "  Precisão da Classe 5: 0.6562\n",
      "Fold 3, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 1.0000\n",
      "  Precisão da Classe 1: 0.4444\n",
      "  Precisão da Classe 2: 0.4186\n",
      "  Precisão da Classe 3: 0.4419\n",
      "  Precisão da Classe 4: 0.6667\n",
      "  Precisão da Classe 5: 0.7500\n",
      "Fold 3, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.4286\n",
      "  Precisão da Classe 2: 0.4694\n",
      "  Precisão da Classe 3: 0.5405\n",
      "  Precisão da Classe 4: 0.7188\n",
      "  Precisão da Classe 5: 0.8148\n",
      "Fold 3, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.4000\n",
      "  Precisão da Classe 1: 0.2308\n",
      "  Precisão da Classe 2: 0.3846\n",
      "  Precisão da Classe 3: 0.4324\n",
      "  Precisão da Classe 4: 0.6471\n",
      "  Precisão da Classe 5: 0.6897\n",
      "Fold 3, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.3962\n",
      "  Precisão da Classe 3: 0.3667\n",
      "  Precisão da Classe 4: 0.6667\n",
      "  Precisão da Classe 5: 0.7241\n",
      "Fold 4, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.2222\n",
      "  Precisão da Classe 1: 0.2222\n",
      "  Precisão da Classe 2: 0.4242\n",
      "  Precisão da Classe 3: 0.3864\n",
      "  Precisão da Classe 4: 0.6071\n",
      "  Precisão da Classe 5: 0.6667\n",
      "Fold 4, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.2308\n",
      "  Precisão da Classe 1: 0.0000\n",
      "  Precisão da Classe 2: 0.5263\n",
      "  Precisão da Classe 3: 0.4390\n",
      "  Precisão da Classe 4: 0.5385\n",
      "  Precisão da Classe 5: 0.7200\n",
      "Fold 4, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.3750\n",
      "  Precisão da Classe 1: 0.4000\n",
      "  Precisão da Classe 2: 0.3714\n",
      "  Precisão da Classe 3: 0.3111\n",
      "  Precisão da Classe 4: 0.4750\n",
      "  Precisão da Classe 5: 0.7826\n",
      "Fold 4, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.2857\n",
      "  Precisão da Classe 1: 0.2000\n",
      "  Precisão da Classe 2: 0.4390\n",
      "  Precisão da Classe 3: 0.3902\n",
      "  Precisão da Classe 4: 0.4722\n",
      "  Precisão da Classe 5: 0.6923\n",
      "Fold 4, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.1667\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.4324\n",
      "  Precisão da Classe 3: 0.4048\n",
      "  Precisão da Classe 4: 0.5000\n",
      "  Precisão da Classe 5: 0.7037\n",
      "Fold 4, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.1667\n",
      "  Precisão da Classe 2: 0.4571\n",
      "  Precisão da Classe 3: 0.4250\n",
      "  Precisão da Classe 4: 0.5641\n",
      "  Precisão da Classe 5: 0.7143\n",
      "Fold 4, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.2222\n",
      "  Precisão da Classe 1: 0.2222\n",
      "  Precisão da Classe 2: 0.4483\n",
      "  Precisão da Classe 3: 0.4091\n",
      "  Precisão da Classe 4: 0.5385\n",
      "  Precisão da Classe 5: 0.7692\n",
      "Fold 5, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.5000\n",
      "  Precisão da Classe 2: 0.5667\n",
      "  Precisão da Classe 3: 0.5556\n",
      "  Precisão da Classe 4: 0.5909\n",
      "  Precisão da Classe 5: 0.6667\n",
      "Fold 5, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.5000\n",
      "  Precisão da Classe 1: 0.5000\n",
      "  Precisão da Classe 2: 0.5263\n",
      "  Precisão da Classe 3: 0.5435\n",
      "  Precisão da Classe 4: 0.6857\n",
      "  Precisão da Classe 5: 0.6774\n",
      "Fold 5, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.2500\n",
      "  Precisão da Classe 2: 0.4857\n",
      "  Precisão da Classe 3: 0.4419\n",
      "  Precisão da Classe 4: 0.5556\n",
      "  Precisão da Classe 5: 0.6400\n",
      "Fold 5, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.6667\n",
      "  Precisão da Classe 1: 0.4286\n",
      "  Precisão da Classe 2: 0.5278\n",
      "  Precisão da Classe 3: 0.5000\n",
      "  Precisão da Classe 4: 0.6429\n",
      "  Precisão da Classe 5: 0.7143\n",
      "Fold 5, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.1667\n",
      "  Precisão da Classe 2: 0.4103\n",
      "  Precisão da Classe 3: 0.4091\n",
      "  Precisão da Classe 4: 0.6098\n",
      "  Precisão da Classe 5: 0.6154\n",
      "Fold 5, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 1.0000\n",
      "  Precisão da Classe 1: 0.2857\n",
      "  Precisão da Classe 2: 0.4412\n",
      "  Precisão da Classe 3: 0.4375\n",
      "  Precisão da Classe 4: 0.5581\n",
      "  Precisão da Classe 5: 0.6957\n",
      "Fold 5, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.5000\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.3824\n",
      "  Precisão da Classe 3: 0.4048\n",
      "  Precisão da Classe 4: 0.6222\n",
      "  Precisão da Classe 5: 0.7200\n",
      "Fold 6, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.1000\n",
      "  Precisão da Classe 2: 0.4737\n",
      "  Precisão da Classe 3: 0.4545\n",
      "  Precisão da Classe 4: 0.5000\n",
      "  Precisão da Classe 5: 0.6667\n",
      "Fold 6, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.1667\n",
      "  Precisão da Classe 2: 0.4359\n",
      "  Precisão da Classe 3: 0.4359\n",
      "  Precisão da Classe 4: 0.4615\n",
      "  Precisão da Classe 5: 0.5556\n",
      "Fold 6, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.2000\n",
      "  Precisão da Classe 2: 0.5143\n",
      "  Precisão da Classe 3: 0.4634\n",
      "  Precisão da Classe 4: 0.4390\n",
      "  Precisão da Classe 5: 0.6400\n",
      "Fold 6, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.2222\n",
      "  Precisão da Classe 2: 0.5484\n",
      "  Precisão da Classe 3: 0.4565\n",
      "  Precisão da Classe 4: 0.5405\n",
      "  Precisão da Classe 5: 0.5862\n",
      "Fold 6, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.2000\n",
      "  Precisão da Classe 1: 0.1250\n",
      "  Precisão da Classe 2: 0.5135\n",
      "  Precisão da Classe 3: 0.5263\n",
      "  Precisão da Classe 4: 0.5714\n",
      "  Precisão da Classe 5: 0.6923\n",
      "Fold 6, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.2000\n",
      "  Precisão da Classe 1: 0.1250\n",
      "  Precisão da Classe 2: 0.5484\n",
      "  Precisão da Classe 3: 0.5000\n",
      "  Precisão da Classe 4: 0.5750\n",
      "  Precisão da Classe 5: 0.7273\n",
      "Fold 6, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.2727\n",
      "  Precisão da Classe 2: 0.5926\n",
      "  Precisão da Classe 3: 0.5111\n",
      "  Precisão da Classe 4: 0.4634\n",
      "  Precisão da Classe 5: 0.6071\n"
     ]
    }
   ],
   "source": [
    "# Exibir precisões de cada classe para cada sub-fold\n",
    "for sub_fold_precision in sub_fold_precisions:\n",
    "    print(f\"Fold {sub_fold_precision['fold']}, Sub-Fold {sub_fold_precision['sub_fold']}:\")\n",
    "    for i, precision in enumerate(sub_fold_precision['precisions']):\n",
    "        print(f\"  Precisão da Classe {i}: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Melhor acurácia no fold 6, sub-fold 2: 0.5961538461538461\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carregar o melhor modelo\n",
    "best_model = load_model(best_model_path)\n",
    "\n",
    "# Fazer previsões no conjunto de teste final\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Gerar a matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_test_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "# Exibir a acurácia final do melhor modelo\n",
    "print(f\"Melhor acurácia no fold {best_fold[0]+1}, sub-fold {best_fold[1]+1}: {best_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão Ponderada:\n",
      "[[0.16666667 0.5        0.33333333 0.         0.         0.        ]\n",
      " [0.1        0.3        0.3        0.2        0.1        0.        ]\n",
      " [0.02777778 0.11111111 0.47222222 0.36111111 0.02777778 0.        ]\n",
      " [0.         0.02439024 0.12195122 0.58536585 0.26829268 0.        ]\n",
      " [0.         0.         0.         0.23684211 0.47368421 0.28947368]\n",
      " [0.         0.         0.         0.         0.32       0.68      ]]\n",
      "Precisão da Classe 0: 0.5660\n",
      "Precisão da Classe 1: 0.3207\n",
      "Precisão da Classe 2: 0.3847\n",
      "Precisão da Classe 3: 0.4232\n",
      "Precisão da Classe 4: 0.3981\n",
      "Precisão da Classe 5: 0.7014\n"
     ]
    }
   ],
   "source": [
    "# Calcular a matriz de confusão original\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred_classes)\n",
    "\n",
    "# Frequência das classes no conjunto de dados\n",
    "class_counts = np.bincount(y_test)  # Conta o número de ocorrências de cada classe\n",
    "class_weights = 1.0 / class_counts  # Calcula o peso de cada classe\n",
    "\n",
    "# Matriz de confusão ponderada\n",
    "weighted_conf_matrix = conf_matrix * class_weights[:, np.newaxis]\n",
    "\n",
    "# Exibir a matriz de confusão ponderada\n",
    "print(\"Matriz de Confusão Ponderada:\")\n",
    "print(weighted_conf_matrix)\n",
    "\n",
    "# Calcular a precisão de cada classe\n",
    "precisions = []\n",
    "for i in range(weighted_conf_matrix.shape[0]):\n",
    "    true_positives = weighted_conf_matrix[i, i]  # Verdadeiros Positivos\n",
    "    false_positives = sum(weighted_conf_matrix[:, i]) - true_positives  # Falsos Positivos\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    precisions.append(precision)\n",
    "\n",
    "# Exibir a precisão de cada classe\n",
    "for idx, precision in enumerate(precisions):\n",
    "    print(f'Precisão da Classe {idx}: {precision:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exibir precisões de cada classe para cada sub-fold\n",
    "# for sub_fold_precision in sub_fold_precisions:\n",
    "#     print(f\"Fold {sub_fold_precision['fold']}, Sub-Fold {sub_fold_precision['sub_fold']}:\")\n",
    "#     for i, precision in enumerate(sub_fold_precision['precisions']):\n",
    "#         print(f\"  Precisão da Classe {i}: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando a precisão de cada classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisao_classe_A = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_A.append(sub_fold_precisions[i]['precisions'][0])\n",
    "\n",
    "precisao_classe_B1 = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_B1.append(sub_fold_precisions[i]['precisions'][1])\n",
    "\n",
    "precisao_classe_B2 = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_B2.append(sub_fold_precisions[i]['precisions'][2])\n",
    "\n",
    "precisao_classe_C1 = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_C1.append(sub_fold_precisions[i]['precisions'][3])\n",
    "\n",
    "precisao_classe_C2 = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_C2.append(sub_fold_precisions[i]['precisions'][4])\n",
    "\n",
    "precisao_classe_DE = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_DE.append(sub_fold_precisions[i]['precisions'][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "precisao_media_DE = statistics.mean(precisao_classe_C2)\n",
    "print(precisao_media_DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Histograma de precisão\n",
    "# nbinsA = int(np.sqrt(len(precisao_classe_A)))\n",
    "# plt.hist(precisao_classe_A, bins = nbinsA, edgecolor='black') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 1: Média de Precisão = 0.3124\n",
      "Classe 2: Média de Precisão = 0.2898\n",
      "Classe 3: Média de Precisão = 0.4717\n",
      "Classe 4: Média de Precisão = 0.4471\n",
      "Classe 5: Média de Precisão = 0.5704\n",
      "Classe 6: Média de Precisão = 0.7024\n"
     ]
    }
   ],
   "source": [
    "# Inicializar uma lista de listas para armazenar as precisões de cada classe\n",
    "precisoes_classes = [[] for _ in range(6)]\n",
    "\n",
    "# Preencher as listas com as precisões obtidas em cada sub-kfold\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    for classe in range(6):\n",
    "        precisoes_classes[classe].append(sub_fold_precisions[i]['precisions'][classe])\n",
    "\n",
    "# Calcular a média de precisão de cada classe\n",
    "media_precisoes_classes = [sum(precisoes)/len(precisoes) for precisoes in precisoes_classes]\n",
    "\n",
    "# Exibir as médias de precisão de cada classe\n",
    "for classe, media in enumerate(media_precisoes_classes):\n",
    "    print(f\"Classe {classe+1}: Média de Precisão = {media:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
