{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando pacotes necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='keras')\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar o modelo de rede neural\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(14, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando a seleção de Dados por k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o arquivo 'dados.csv' no dataframe\n",
    "df_kfold = pd.read_csv('df_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis objetivo\n",
    "X = df_kfold.drop('CLASSE', axis=1)\n",
    "y = df_kfold['CLASSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo o número de folds\n",
    "\n",
    "num_folds = 7\n",
    "sub_num_folds = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar o k-Fold Principal\n",
    "\n",
    "kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir os Dados para o k-fold teste\n",
    "\n",
    "fold_indices = list(kf.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre cada fold principal\n",
    "for fold, (train_index, test_index) in enumerate(fold_indices):\n",
    "    # Dados de treino e teste para o fold principal\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Aplicar o sub-k-fold para treino e validação\n",
    "    sub_kf = StratifiedKFold(n_splits=sub_num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Armazenar os índices dos folds secundários\n",
    "    sub_fold_indices = list(sub_kf.split(X_train, y_train))\n",
    "\n",
    "    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_fold_indices):\n",
    "        # Dados de treino e validação para o sub-k-fold\n",
    "        X_sub_train, X_sub_val = X_train.iloc[sub_train_index], X_train.iloc[sub_val_index]\n",
    "        y_sub_train, y_sub_val = y_train.iloc[sub_train_index], y_train.iloc[sub_val_index]\n",
    "\n",
    "        # Aqui você pode treinar e validar seu modelo\n",
    "        # Exemplo: print(f'Fold {fold + 1}, Sub-Fold {sub_fold + 1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando disposição das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import pandas as pd\n",
    "\n",
    "# # Exemplo de dataframe com rótulos (alvo)\n",
    "# y = pd.Series(y)  # Supondo que seus rótulos estejam em um array ou lista chamada 'y'\n",
    "\n",
    "# # Inicializar o StratifiedKFold\n",
    "# kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# # Iterar pelos folds principais\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     # Contagem das classes no treino e teste\n",
    "#     train_counts = Counter(y_train)\n",
    "#     test_counts = Counter(y_test)\n",
    "    \n",
    "#     # print(f\"Fold {fold + 1}\")\n",
    "#     # print(f\"Distribuição no treino: {train_counts}\")\n",
    "#     # print(f\"Distribuição no teste: {test_counts}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Distribuição no treino: Counter({'C1': 251, 'C2': 224, 'B2': 214, 'DE': 151, 'B1': 65, 'A': 34})\n",
      "Distribuição no teste: Counter({'C1': 42, 'C2': 38, 'B2': 36, 'DE': 25, 'B1': 10, 'A': 6})\n",
      "\n",
      "  Subfold 1\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 10, 'A': 5})\n",
      "\n",
      "  Subfold 2\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 10, 'A': 4})\n",
      "\n",
      "  Subfold 3\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 183, 'DE': 130, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 4\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 5\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 6\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 7\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 183, 'DE': 129, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 35, 'C2': 32, 'B2': 31, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "Fold 2\n",
      "Distribuição no treino: Counter({'C1': 251, 'C2': 224, 'B2': 215, 'DE': 151, 'B1': 64, 'A': 34})\n",
      "Distribuição no teste: Counter({'C1': 42, 'C2': 38, 'B2': 35, 'DE': 25, 'B1': 11, 'A': 6})\n",
      "\n",
      "  Subfold 1\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 2\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 185, 'DE': 129, 'B1': 54, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 10, 'A': 4})\n",
      "\n",
      "  Subfold 3\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 185, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 4\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 184, 'DE': 130, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 5\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 184, 'DE': 130, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 6\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 184, 'DE': 130, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 7\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 35, 'C2': 32, 'B2': 31, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "Fold 3\n",
      "Distribuição no treino: Counter({'C1': 251, 'C2': 225, 'B2': 215, 'DE': 150, 'B1': 64, 'A': 34})\n",
      "Distribuição no teste: Counter({'C1': 42, 'C2': 37, 'B2': 35, 'DE': 26, 'B1': 11, 'A': 6})\n",
      "\n",
      "  Subfold 1\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 33, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 2\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 193, 'B2': 184, 'DE': 128, 'B1': 54, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 35, 'C2': 32, 'B2': 31, 'DE': 22, 'B1': 10, 'A': 4})\n",
      "\n",
      "  Subfold 3\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 185, 'DE': 128, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 4\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 185, 'DE': 128, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 5\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 6\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 7\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "Fold 4\n",
      "Distribuição no treino: Counter({'C1': 251, 'C2': 225, 'B2': 214, 'DE': 151, 'B1': 64, 'A': 34})\n",
      "Distribuição no teste: Counter({'C1': 42, 'C2': 37, 'B2': 36, 'DE': 25, 'B1': 11, 'A': 6})\n",
      "\n",
      "  Subfold 1\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 33, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 2\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 54, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 10, 'A': 4})\n",
      "\n",
      "  Subfold 3\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 4\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 5\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 6\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 7\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 193, 'B2': 183, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 35, 'C2': 32, 'B2': 31, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "Fold 5\n",
      "Distribuição no treino: Counter({'C1': 251, 'C2': 225, 'B2': 214, 'DE': 151, 'B1': 64, 'A': 35})\n",
      "Distribuição no teste: Counter({'C1': 42, 'C2': 37, 'B2': 36, 'DE': 25, 'B1': 11, 'A': 5})\n",
      "\n",
      "  Subfold 1\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 183, 'DE': 129, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 2\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 54, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 10, 'A': 5})\n",
      "\n",
      "  Subfold 3\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 4\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 5\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 6\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 7\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 35, 'C2': 33, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "Fold 6\n",
      "Distribuição no treino: Counter({'C1': 251, 'C2': 225, 'B2': 214, 'DE': 151, 'B1': 64, 'A': 35})\n",
      "Distribuição no teste: Counter({'C1': 42, 'C2': 37, 'B2': 36, 'DE': 25, 'B1': 11, 'A': 5})\n",
      "\n",
      "  Subfold 1\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 183, 'DE': 129, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 2\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 54, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 10, 'A': 5})\n",
      "\n",
      "  Subfold 3\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 4\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 5\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 6\n",
      "  Distribuição no treino: Counter({'C1': 215, 'C2': 193, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 7\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 183, 'DE': 130, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 35, 'C2': 33, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "Fold 7\n",
      "Distribuição no treino: Counter({'C1': 252, 'C2': 224, 'B2': 214, 'DE': 151, 'B1': 65, 'A': 34})\n",
      "Distribuição no teste: Counter({'C1': 41, 'C2': 38, 'B2': 36, 'DE': 25, 'B1': 10, 'A': 6})\n",
      "\n",
      "  Subfold 1\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 183, 'DE': 129, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 2\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 10, 'A': 5})\n",
      "\n",
      "  Subfold 3\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 55, 'A': 30})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 10, 'A': 4})\n",
      "\n",
      "  Subfold 4\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 184, 'DE': 129, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 30, 'DE': 22, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 5\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 183, 'DE': 130, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 6\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 183, 'DE': 130, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n",
      "  Subfold 7\n",
      "  Distribuição no treino: Counter({'C1': 216, 'C2': 192, 'B2': 183, 'DE': 130, 'B1': 56, 'A': 29})\n",
      "  Distribuição na validação: Counter({'C1': 36, 'C2': 32, 'B2': 31, 'DE': 21, 'B1': 9, 'A': 5})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aqui é só pra contar e ver a proporção dos Folds e Subfolds\n",
    "\n",
    "# Suponha que X seja um DataFrame e y seja uma Series\n",
    "# Se X é um DataFrame e y é uma Series\n",
    "kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterar pelos folds principais\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Contagem das classes no treino e teste\n",
    "    train_counts = Counter(y_train)\n",
    "    test_counts = Counter(y_test)\n",
    "    \n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(f\"Distribuição no treino: {train_counts}\")\n",
    "    print(f\"Distribuição no teste: {test_counts}\\n\")\n",
    "\n",
    "    # Subdividir o treino em subfolds\n",
    "    sub_kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "    \n",
    "    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_kfold.split(X_train, y_train)):\n",
    "        y_sub_train = y_train.iloc[sub_train_index]\n",
    "        y_sub_val = y_train.iloc[sub_val_index]\n",
    "        \n",
    "        # Contagem das classes nos subfolds\n",
    "        sub_train_counts = Counter(y_sub_train)\n",
    "        sub_val_counts = Counter(y_sub_val)\n",
    "        \n",
    "        print(f\"  Subfold {sub_fold + 1}\")\n",
    "        print(f\"  Distribuição no treino: {sub_train_counts}\")\n",
    "        print(f\"  Distribuição na validação: {sub_val_counts}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando as redes neurais no k-fold do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar as métricas de avaliação\n",
    "validation_reports = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"best_model.keras\"  # Local para salvar o melhor modelo\n",
    "\n",
    "# Configurar o callback para salvar o melhor modelo com base na métrica de validação\n",
    "checkpoint = ModelCheckpoint(best_model_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Variável para armazenar o melhor desempenho\n",
    "best_val_accuracy = 0\n",
    "best_fold = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar uma lista para armazenar a precisão ponderada de cada fold\n",
    "fold_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir precisões ponderadas de cada fold\n",
    "for accuracy in fold_accuracies:\n",
    "    print(f\"Fold {accuracy['fold']}, Sub-Fold {accuracy['sub_fold']}: Acurácia de Teste = {accuracy['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar os rótulos para garantir que estejam no intervalo esperado\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027873415B20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027873415B20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "# Armazenar as precisões por classe para cada sub-fold\n",
    "sub_fold_precisions = []\n",
    "\n",
    "# Exibir a precisão de cada classe\n",
    "for fold, (train_index, test_index) in enumerate(fold_indices):\n",
    "    # Dados de treino e teste para o fold principal\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Aplicar Sub-K-Fold para treino e validação\n",
    "    sub_fold_indices = list(sub_kf.split(X_train, y_train))\n",
    "    \n",
    "    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_fold_indices):\n",
    "        # Dados de treino e validação para o sub-k-fold\n",
    "        X_sub_train, X_sub_val = X_train.iloc[sub_train_index], X_train.iloc[sub_val_index]\n",
    "        y_sub_train, y_sub_val = y_train[sub_train_index], y_train[sub_val_index]\n",
    "        \n",
    "        # Criar o modelo\n",
    "        num_classes = len(label_encoder.classes_)\n",
    "        model = create_model(X.shape[1], num_classes)\n",
    "        \n",
    "        # Treinar o modelo e salvar o histórico\n",
    "        history = model.fit(\n",
    "            X_sub_train, y_sub_train, \n",
    "            epochs=100, batch_size=32, \n",
    "            verbose=0, validation_data=(X_sub_val, y_sub_val),\n",
    "            callbacks=[checkpoint]\n",
    "        )\n",
    "\n",
    "        # Avaliar no conjunto de teste\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "        # Calcular acurácia de teste\n",
    "        test_accuracy = np.mean(y_test_pred_classes == y_test)\n",
    "\n",
    "        # Atualizar o melhor modelo se este fold for melhor\n",
    "        if test_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = test_accuracy\n",
    "            best_fold = (fold, sub_fold)\n",
    "        \n",
    "        # Calcular a matriz de confusão\n",
    "        cm = confusion_matrix(y_test, y_test_pred_classes, labels=np.arange(num_classes))\n",
    "        \n",
    "        # Calcular a precisão de cada classe\n",
    "        class_precisions = precision_score(y_test, y_test_pred_classes, average=None)\n",
    "        \n",
    "        # Armazenar a precisão de cada classe para o sub-fold\n",
    "        sub_fold_precisions.append({\n",
    "            'fold': fold,\n",
    "            'sub_fold': sub_fold,\n",
    "            'precisions': class_precisions\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.1667\n",
      "  Precisão da Classe 1: 0.4000\n",
      "  Precisão da Classe 2: 0.5152\n",
      "  Precisão da Classe 3: 0.4565\n",
      "  Precisão da Classe 4: 0.6053\n",
      "  Precisão da Classe 5: 0.6522\n",
      "Fold 0, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.6667\n",
      "  Precisão da Classe 1: 0.5000\n",
      "  Precisão da Classe 2: 0.4419\n",
      "  Precisão da Classe 3: 0.4694\n",
      "  Precisão da Classe 4: 0.6111\n",
      "  Precisão da Classe 5: 0.6250\n",
      "Fold 0, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.5000\n",
      "  Precisão da Classe 2: 0.5000\n",
      "  Precisão da Classe 3: 0.5435\n",
      "  Precisão da Classe 4: 0.6842\n",
      "  Precisão da Classe 5: 0.6957\n",
      "Fold 0, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.2500\n",
      "  Precisão da Classe 2: 0.4524\n",
      "  Precisão da Classe 3: 0.4318\n",
      "  Precisão da Classe 4: 0.5814\n",
      "  Precisão da Classe 5: 0.6667\n",
      "Fold 0, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.4722\n",
      "  Precisão da Classe 3: 0.4878\n",
      "  Precisão da Classe 4: 0.5106\n",
      "  Precisão da Classe 5: 0.6522\n",
      "Fold 0, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.5000\n",
      "  Precisão da Classe 1: 0.2000\n",
      "  Precisão da Classe 2: 0.3721\n",
      "  Precisão da Classe 3: 0.4651\n",
      "  Precisão da Classe 4: 0.5714\n",
      "  Precisão da Classe 5: 0.6500\n",
      "Fold 0, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.4286\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.4571\n",
      "  Precisão da Classe 3: 0.4792\n",
      "  Precisão da Classe 4: 0.6190\n",
      "  Precisão da Classe 5: 0.7727\n",
      "Fold 1, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.1667\n",
      "  Precisão da Classe 2: 0.4524\n",
      "  Precisão da Classe 3: 0.4792\n",
      "  Precisão da Classe 4: 0.5405\n",
      "  Precisão da Classe 5: 0.7500\n",
      "Fold 1, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.2222\n",
      "  Precisão da Classe 2: 0.4250\n",
      "  Precisão da Classe 3: 0.3778\n",
      "  Precisão da Classe 4: 0.5000\n",
      "  Precisão da Classe 5: 0.7778\n",
      "Fold 1, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.1429\n",
      "  Precisão da Classe 2: 0.4651\n",
      "  Precisão da Classe 3: 0.3902\n",
      "  Precisão da Classe 4: 0.5000\n",
      "  Precisão da Classe 5: 0.7778\n",
      "Fold 1, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.3077\n",
      "  Precisão da Classe 2: 0.3778\n",
      "  Precisão da Classe 3: 0.3902\n",
      "  Precisão da Classe 4: 0.5000\n",
      "  Precisão da Classe 5: 0.7500\n",
      "Fold 1, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.2000\n",
      "  Precisão da Classe 1: 0.2000\n",
      "  Precisão da Classe 2: 0.4894\n",
      "  Precisão da Classe 3: 0.4444\n",
      "  Precisão da Classe 4: 0.5111\n",
      "  Precisão da Classe 5: 0.6842\n",
      "Fold 1, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.1667\n",
      "  Precisão da Classe 2: 0.4186\n",
      "  Precisão da Classe 3: 0.4103\n",
      "  Precisão da Classe 4: 0.5455\n",
      "  Precisão da Classe 5: 0.7273\n",
      "Fold 1, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.2000\n",
      "  Precisão da Classe 1: 0.4286\n",
      "  Precisão da Classe 2: 0.4706\n",
      "  Precisão da Classe 3: 0.5000\n",
      "  Precisão da Classe 4: 0.5745\n",
      "  Precisão da Classe 5: 0.7727\n",
      "Fold 2, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.1667\n",
      "  Precisão da Classe 1: 0.2222\n",
      "  Precisão da Classe 2: 0.6061\n",
      "  Precisão da Classe 3: 0.5227\n",
      "  Precisão da Classe 4: 0.5556\n",
      "  Precisão da Classe 5: 0.6552\n",
      "Fold 2, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.6000\n",
      "  Precisão da Classe 1: 0.1429\n",
      "  Precisão da Classe 2: 0.4857\n",
      "  Precisão da Classe 3: 0.4792\n",
      "  Precisão da Classe 4: 0.5312\n",
      "  Precisão da Classe 5: 0.6333\n",
      "Fold 2, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.1111\n",
      "  Precisão da Classe 2: 0.5500\n",
      "  Precisão da Classe 3: 0.4848\n",
      "  Precisão da Classe 4: 0.5250\n",
      "  Precisão da Classe 5: 0.6129\n",
      "Fold 2, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.0000\n",
      "  Precisão da Classe 2: 0.5938\n",
      "  Precisão da Classe 3: 0.4792\n",
      "  Precisão da Classe 4: 0.5143\n",
      "  Precisão da Classe 5: 0.6552\n",
      "Fold 2, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.2857\n",
      "  Precisão da Classe 2: 0.5806\n",
      "  Precisão da Classe 3: 0.5200\n",
      "  Precisão da Classe 4: 0.5357\n",
      "  Precisão da Classe 5: 0.5714\n",
      "Fold 2, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.6667\n",
      "  Precisão da Classe 1: 0.2500\n",
      "  Precisão da Classe 2: 0.4865\n",
      "  Precisão da Classe 3: 0.5238\n",
      "  Precisão da Classe 4: 0.6061\n",
      "  Precisão da Classe 5: 0.6333\n",
      "Fold 2, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.1429\n",
      "  Precisão da Classe 1: 0.2000\n",
      "  Precisão da Classe 2: 0.5000\n",
      "  Precisão da Classe 3: 0.5128\n",
      "  Precisão da Classe 4: 0.5263\n",
      "  Precisão da Classe 5: 0.6207\n",
      "Fold 3, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.1250\n",
      "  Precisão da Classe 2: 0.4082\n",
      "  Precisão da Classe 3: 0.4571\n",
      "  Precisão da Classe 4: 0.6250\n",
      "  Precisão da Classe 5: 0.6875\n",
      "Fold 3, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.2222\n",
      "  Precisão da Classe 2: 0.3800\n",
      "  Precisão da Classe 3: 0.3714\n",
      "  Precisão da Classe 4: 0.5714\n",
      "  Precisão da Classe 5: 0.7308\n",
      "Fold 3, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.5000\n",
      "  Precisão da Classe 1: 0.3529\n",
      "  Precisão da Classe 2: 0.4286\n",
      "  Precisão da Classe 3: 0.4848\n",
      "  Precisão da Classe 4: 0.6842\n",
      "  Precisão da Classe 5: 0.8000\n",
      "Fold 3, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.5000\n",
      "  Precisão da Classe 3: 0.4545\n",
      "  Precisão da Classe 4: 0.7308\n",
      "  Precisão da Classe 5: 0.7419\n",
      "Fold 3, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.3750\n",
      "  Precisão da Classe 2: 0.4889\n",
      "  Precisão da Classe 3: 0.5143\n",
      "  Precisão da Classe 4: 0.7500\n",
      "  Precisão da Classe 5: 0.7586\n",
      "Fold 3, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.2500\n",
      "  Precisão da Classe 2: 0.5094\n",
      "  Precisão da Classe 3: 0.5000\n",
      "  Precisão da Classe 4: 0.6111\n",
      "  Precisão da Classe 5: 0.7407\n",
      "Fold 3, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.2222\n",
      "  Precisão da Classe 2: 0.4667\n",
      "  Precisão da Classe 3: 0.4500\n",
      "  Precisão da Classe 4: 0.6897\n",
      "  Precisão da Classe 5: 0.7419\n",
      "Fold 4, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.2857\n",
      "  Precisão da Classe 2: 0.3824\n",
      "  Precisão da Classe 3: 0.3488\n",
      "  Precisão da Classe 4: 0.5278\n",
      "  Precisão da Classe 5: 0.7407\n",
      "Fold 4, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.4444\n",
      "  Precisão da Classe 1: 1.0000\n",
      "  Precisão da Classe 2: 0.4884\n",
      "  Precisão da Classe 3: 0.4146\n",
      "  Precisão da Classe 4: 0.5429\n",
      "  Precisão da Classe 5: 0.7407\n",
      "Fold 4, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.1111\n",
      "  Precisão da Classe 1: 0.4286\n",
      "  Precisão da Classe 2: 0.4828\n",
      "  Precisão da Classe 3: 0.4286\n",
      "  Precisão da Classe 4: 0.6000\n",
      "  Precisão da Classe 5: 0.7407\n",
      "Fold 4, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.1250\n",
      "  Precisão da Classe 1: 0.0000\n",
      "  Precisão da Classe 2: 0.4048\n",
      "  Precisão da Classe 3: 0.4516\n",
      "  Precisão da Classe 4: 0.4667\n",
      "  Precisão da Classe 5: 0.6923\n",
      "Fold 4, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.1429\n",
      "  Precisão da Classe 1: 0.2857\n",
      "  Precisão da Classe 2: 0.4634\n",
      "  Precisão da Classe 3: 0.4500\n",
      "  Precisão da Classe 4: 0.5556\n",
      "  Precisão da Classe 5: 0.7600\n",
      "Fold 4, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.1667\n",
      "  Precisão da Classe 1: 0.1667\n",
      "  Precisão da Classe 2: 0.5000\n",
      "  Precisão da Classe 3: 0.4286\n",
      "  Precisão da Classe 4: 0.5789\n",
      "  Precisão da Classe 5: 0.7308\n",
      "Fold 4, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.2500\n",
      "  Precisão da Classe 2: 0.4211\n",
      "  Precisão da Classe 3: 0.3636\n",
      "  Precisão da Classe 4: 0.4595\n",
      "  Precisão da Classe 5: 0.7200\n",
      "Fold 5, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 1.0000\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.3714\n",
      "  Precisão da Classe 3: 0.4444\n",
      "  Precisão da Classe 4: 0.5745\n",
      "  Precisão da Classe 5: 0.7273\n",
      "Fold 5, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.4000\n",
      "  Precisão da Classe 2: 0.4865\n",
      "  Precisão da Classe 3: 0.4255\n",
      "  Precisão da Classe 4: 0.5581\n",
      "  Precisão da Classe 5: 0.7826\n",
      "Fold 5, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.4000\n",
      "  Precisão da Classe 2: 0.4828\n",
      "  Precisão da Classe 3: 0.4468\n",
      "  Precisão da Classe 4: 0.5417\n",
      "  Precisão da Classe 5: 0.6522\n",
      "Fold 5, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.5455\n",
      "  Precisão da Classe 3: 0.5238\n",
      "  Precisão da Classe 4: 0.5532\n",
      "  Precisão da Classe 5: 0.6800\n",
      "Fold 5, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 1.0000\n",
      "  Precisão da Classe 1: 0.1667\n",
      "  Precisão da Classe 2: 0.5000\n",
      "  Precisão da Classe 3: 0.4118\n",
      "  Precisão da Classe 4: 0.5610\n",
      "  Precisão da Classe 5: 0.6800\n",
      "Fold 5, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.5000\n",
      "  Precisão da Classe 1: 0.5000\n",
      "  Precisão da Classe 2: 0.5625\n",
      "  Precisão da Classe 3: 0.5217\n",
      "  Precisão da Classe 4: 0.5556\n",
      "  Precisão da Classe 5: 0.7391\n",
      "Fold 5, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.0000\n",
      "  Precisão da Classe 1: 0.5000\n",
      "  Precisão da Classe 2: 0.4571\n",
      "  Precisão da Classe 3: 0.4400\n",
      "  Precisão da Classe 4: 0.6000\n",
      "  Precisão da Classe 5: 0.7500\n",
      "Fold 6, Sub-Fold 0:\n",
      "  Precisão da Classe 0: 0.5000\n",
      "  Precisão da Classe 1: 0.3333\n",
      "  Precisão da Classe 2: 0.4483\n",
      "  Precisão da Classe 3: 0.4667\n",
      "  Precisão da Classe 4: 0.5333\n",
      "  Precisão da Classe 5: 0.6400\n",
      "Fold 6, Sub-Fold 1:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.1250\n",
      "  Precisão da Classe 2: 0.4857\n",
      "  Precisão da Classe 3: 0.4444\n",
      "  Precisão da Classe 4: 0.5278\n",
      "  Precisão da Classe 5: 0.6207\n",
      "Fold 6, Sub-Fold 2:\n",
      "  Precisão da Classe 0: 0.4000\n",
      "  Precisão da Classe 1: 0.1818\n",
      "  Precisão da Classe 2: 0.4571\n",
      "  Precisão da Classe 3: 0.4444\n",
      "  Precisão da Classe 4: 0.5000\n",
      "  Precisão da Classe 5: 0.6818\n",
      "Fold 6, Sub-Fold 3:\n",
      "  Precisão da Classe 0: 0.3333\n",
      "  Precisão da Classe 1: 0.4000\n",
      "  Precisão da Classe 2: 0.4865\n",
      "  Precisão da Classe 3: 0.4419\n",
      "  Precisão da Classe 4: 0.5789\n",
      "  Precisão da Classe 5: 0.6667\n",
      "Fold 6, Sub-Fold 4:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.2500\n",
      "  Precisão da Classe 2: 0.5405\n",
      "  Precisão da Classe 3: 0.4419\n",
      "  Precisão da Classe 4: 0.5556\n",
      "  Precisão da Classe 5: 0.7500\n",
      "Fold 6, Sub-Fold 5:\n",
      "  Precisão da Classe 0: 0.2500\n",
      "  Precisão da Classe 1: 0.3000\n",
      "  Precisão da Classe 2: 0.5926\n",
      "  Precisão da Classe 3: 0.4348\n",
      "  Precisão da Classe 4: 0.5366\n",
      "  Precisão da Classe 5: 0.7500\n",
      "Fold 6, Sub-Fold 6:\n",
      "  Precisão da Classe 0: 0.4000\n",
      "  Precisão da Classe 1: 0.3750\n",
      "  Precisão da Classe 2: 0.6296\n",
      "  Precisão da Classe 3: 0.4717\n",
      "  Precisão da Classe 4: 0.5135\n",
      "  Precisão da Classe 5: 0.6538\n"
     ]
    }
   ],
   "source": [
    "# Exibir precisões de cada classe para cada sub-fold\n",
    "for sub_fold_precision in sub_fold_precisions:\n",
    "    print(f\"Fold {sub_fold_precision['fold']}, Sub-Fold {sub_fold_precision['sub_fold']}:\")\n",
    "    for i, precision in enumerate(sub_fold_precision['precisions']):\n",
    "        print(f\"  Precisão da Classe {i}: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Melhor acurácia no fold 4, sub-fold 5: 0.5859872611464968\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carregar o melhor modelo\n",
    "best_model = load_model(best_model_path)\n",
    "\n",
    "# Fazer previsões no conjunto de teste final\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Gerar a matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_test_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "# Exibir a acurácia final do melhor modelo\n",
    "print(f\"Melhor acurácia no fold {best_fold[0]+1}, sub-fold {best_fold[1]+1}: {best_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relatório de Classificação (Matriz):\n",
      "              precision    recall  f1-score     support\n",
      "A              0.333333  0.166667  0.222222    6.000000\n",
      "B1             0.333333  0.200000  0.250000   10.000000\n",
      "B2             0.516129  0.444444  0.477612   36.000000\n",
      "C1             0.479167  0.560976  0.516854   41.000000\n",
      "C2             0.594595  0.578947  0.586667   38.000000\n",
      "DE             0.612903  0.760000  0.678571   25.000000\n",
      "accuracy       0.532051  0.532051  0.532051    0.532051\n",
      "macro avg      0.478243  0.451839  0.455321  156.000000\n",
      "weighted avg   0.522288  0.532051  0.522282  156.000000\n",
      "\n",
      "Melhor acurácia no fold 4, sub-fold 5: 0.5859872611464968\n"
     ]
    }
   ],
   "source": [
    "# Gerar o relatório de classificação\n",
    "report = classification_report(y_test, y_test_pred_classes, target_names=label_encoder.classes_, output_dict=True)\n",
    "\n",
    "# Converter o relatório em um DataFrame para exibição como matriz\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Exibir o relatório em formato de matriz\n",
    "print(\"\\nRelatório de Classificação (Matriz):\")\n",
    "print(report_df)\n",
    "\n",
    "# Exibir a acurácia final do melhor modelo\n",
    "print(f\"\\nMelhor acurácia no fold {best_fold[0]+1}, sub-fold {best_fold[1]+1}: {best_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão Ponderada:\n",
      "[[0.16666667 0.33333333 0.33333333 0.16666667 0.         0.        ]\n",
      " [0.1        0.2        0.4        0.2        0.1        0.        ]\n",
      " [0.02777778 0.05555556 0.44444444 0.44444444 0.02777778 0.        ]\n",
      " [0.         0.         0.19512195 0.56097561 0.19512195 0.04878049]\n",
      " [0.         0.         0.         0.15789474 0.57894737 0.26315789]\n",
      " [0.         0.         0.04       0.         0.2        0.76      ]]\n",
      "Precisão da Classe 0: 0.5660\n",
      "Precisão da Classe 1: 0.3396\n",
      "Precisão da Classe 2: 0.3146\n",
      "Precisão da Classe 3: 0.3667\n",
      "Precisão da Classe 4: 0.5254\n",
      "Precisão da Classe 5: 0.7090\n"
     ]
    }
   ],
   "source": [
    "# Calcular a matriz de confusão original\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred_classes)\n",
    "\n",
    "# Frequência das classes no conjunto de dados\n",
    "class_counts = np.bincount(y_test)  # Conta o número de ocorrências de cada classe\n",
    "class_weights = 1.0 / class_counts  # Calcula o peso de cada classe\n",
    "\n",
    "# Matriz de confusão ponderada\n",
    "weighted_conf_matrix = conf_matrix * class_weights[:, np.newaxis]\n",
    "\n",
    "# Exibir a matriz de confusão ponderada\n",
    "print(\"Matriz de Confusão Ponderada:\")\n",
    "print(weighted_conf_matrix)\n",
    "\n",
    "# Calcular a precisão de cada classe\n",
    "precisions = []\n",
    "for i in range(weighted_conf_matrix.shape[0]):\n",
    "    true_positives = weighted_conf_matrix[i, i]  # Verdadeiros Positivos\n",
    "    false_positives = sum(weighted_conf_matrix[:, i]) - true_positives  # Falsos Positivos\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    precisions.append(precision)\n",
    "\n",
    "# Exibir a precisão de cada classe\n",
    "for idx, precision in enumerate(precisions):\n",
    "    print(f'Precisão da Classe {idx}: {precision:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exibir precisões de cada classe para cada sub-fold\n",
    "# for sub_fold_precision in sub_fold_precisions:\n",
    "#     print(f\"Fold {sub_fold_precision['fold']}, Sub-Fold {sub_fold_precision['sub_fold']}:\")\n",
    "#     for i, precision in enumerate(sub_fold_precision['precisions']):\n",
    "#         print(f\"  Precisão da Classe {i}: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando a precisão de cada classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisao_classe_A = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_A.append(sub_fold_precisions[i]['precisions'][0])\n",
    "\n",
    "precisao_classe_B1 = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_B1.append(sub_fold_precisions[i]['precisions'][1])\n",
    "\n",
    "precisao_classe_B2 = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_B2.append(sub_fold_precisions[i]['precisions'][2])\n",
    "\n",
    "precisao_classe_C1 = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_C1.append(sub_fold_precisions[i]['precisions'][3])\n",
    "\n",
    "precisao_classe_C2 = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_C2.append(sub_fold_precisions[i]['precisions'][4])\n",
    "\n",
    "precisao_classe_DE = []\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    precisao_classe_DE.append(sub_fold_precisions[i]['precisions'][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Histograma de precisão\n",
    "# nbinsA = int(np.sqrt(len(precisao_classe_A)))\n",
    "# plt.hist(precisao_classe_A, bins = nbinsA, edgecolor='black') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'statistics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Calcular a média de precisão de cada classe\u001b[39;00m\n\u001b[0;32m     10\u001b[0m media_precisoes_classes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msum\u001b[39m(precisoes)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(precisoes) \u001b[38;5;28;01mfor\u001b[39;00m precisoes \u001b[38;5;129;01min\u001b[39;00m precisoes_classes]\n\u001b[1;32m---> 11\u001b[0m desvio_padrao_precisoes_classes \u001b[38;5;241m=\u001b[39m [\u001b[43mstatistics\u001b[49m\u001b[38;5;241m.\u001b[39mstdev(precisoes) \u001b[38;5;28;01mfor\u001b[39;00m precisoes \u001b[38;5;129;01min\u001b[39;00m precisoes_classes]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Exibir as médias de precisão de cada classe\u001b[39;00m\n\u001b[0;32m     14\u001b[0m vetor_classe \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDE\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'statistics' is not defined"
     ]
    }
   ],
   "source": [
    "# Inicializar uma lista de listas para armazenar as precisões de cada classe\n",
    "precisoes_classes = [[] for _ in range(6)]\n",
    "\n",
    "# Preencher as listas com as precisões obtidas em cada sub-kfold\n",
    "for i in range(len(sub_fold_precisions)):\n",
    "    for classe in range(6):\n",
    "        precisoes_classes[classe].append(sub_fold_precisions[i]['precisions'][classe])\n",
    "\n",
    "# Calcular a média de precisão de cada classe\n",
    "media_precisoes_classes = [sum(precisoes)/len(precisoes) for precisoes in precisoes_classes]\n",
    "desvio_padrao_precisoes_classes = [statistics.stdev(precisoes) for precisoes in precisoes_classes]\n",
    "\n",
    "# Exibir as médias de precisão de cada classe\n",
    "vetor_classe = [\"A\", \"B1\", \"B2\", \"C1\", \"C2\", \"DE\"]\n",
    "for classe, media in enumerate(media_precisoes_classes):\n",
    "    # print(f\"Classe {classe+1}: Média de Precisão = {media:.4f}\")\n",
    "    print(f\"Classe {vetor_classe[classe]}: Média de Precisão = {media:.4f}, Desvio Padrão = {desvio:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
