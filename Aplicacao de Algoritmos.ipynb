{"cells":[{"cell_type":"code","execution_count":94,"metadata":{"id":"CYGTBxtwdNfu"},"outputs":[],"source":["# Importando pacotes necessários\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.model_selection import StratifiedKFold\n","\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","\n","from scipy.stats import spearmanr\n","\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37115,"status":"ok","timestamp":1726517485079,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"ntS0T5EGdU3C","outputId":"67a776f7-8e3a-45c7-b31b-7892ff81a458"},"outputs":[],"source":["## Utilizar esse caso esteja usando o Google Colab\n","\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","#Carregar arquivo do drive\n","#df = pd.read_csv('/content/drive/MyDrive/Períodos/2024-2/Aprendizado de Máquina/Projeto/dados.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6eUiHcdYdNf1"},"outputs":[],"source":["# Carregar o arquivo 'dados.csv' no dataframe\n","df = pd.read_csv('dados.csv')\n","\n","# Exibir as primeiras linhas do dataframe para verificar se foi carregado corretamente\n","print(df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Criar um dicionário de mapeamento\n","classe_map = {1: 'A', 2: 'B1', 3: 'B2', 4: 'C1', 5: 'C2', 6: 'DE'}\n","\n","# Substituir os valores da coluna 'CLASSE'\n","df['CLASSE'] = df['CLASSE'].map(classe_map)\n","\n","# Verificar a alteração\n","print(df['CLASSE'].unique())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["contagem = df['CLASSE'].value_counts()\n","print(contagem)\n"]},{"cell_type":"markdown","metadata":{"id":"9rjyP69tdNf1"},"source":["Aplicando o PCA"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"1yPvVpCbdNf5"},"outputs":[],"source":["# Separar as variáveis independentes (X) e a variável dependente (y)\n","dados_sem_classe = df.drop('CLASSE', axis=1)\n","classe_1 = df['CLASSE']"]},{"cell_type":"code","execution_count":105,"metadata":{"id":"oUHEqrwTdNf6"},"outputs":[],"source":["# Padronizar os dados antes de aplicar o PCA\n","scaler = StandardScaler()\n","dadosPCA_scaled = scaler.fit_transform(dados_sem_classe)"]},{"cell_type":"code","execution_count":106,"metadata":{"id":"KzvI9zEKdNf7"},"outputs":[],"source":["# Aplicar PCA\n","pca = PCA()\n","dadosPCA_reduced = pca.fit_transform(dadosPCA_scaled)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Y6TIk1gwdNf8"},"outputs":[],"source":["# Variância explicada por cada componente\n","explained_variance = pca.explained_variance_ratio_"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"1FjmaqtqdNf9"},"outputs":[],"source":["# Variância acumulada\n","cumulative_variance = np.cumsum(explained_variance)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":565},"executionInfo":{"elapsed":827,"status":"ok","timestamp":1726518016096,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"lTKmM3xgdNf-","outputId":"973f86ab-0216-44bf-d6e0-10e79109129e"},"outputs":[],"source":["# Plotar a variância explicada e a acumulada em gráficos de barras\n","plt.figure(figsize=(10, 6))\n","\n","# Gráfico de barras para a variância explicada\n","plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, label='Variância Explicada (%)')\n","plt.title('Análise de Variância com PCA')\n","plt.xlabel('Número de Componentes Principais')\n","plt.ylabel('Porcentagem de Variância (%)')\n","plt.legend(loc='best')\n","plt.grid(True)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":276,"status":"ok","timestamp":1726518021477,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"rsinx1lHdNf_","outputId":"9fc600e0-cfef-4257-ad4f-4b51e06e6bed"},"outputs":[],"source":["# Encontrar o número de componentes que explicam\n","n_components = np.argmax(cumulative_variance >= 0.8) + 1\n","\n","print(f\"Número de componentes principais: {n_components}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":753,"status":"ok","timestamp":1726518026161,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"wRxd17f0dNgA","outputId":"aa903ae7-e139-4ce3-dd72-8da39604174a"},"outputs":[],"source":["# Gráfico de linha para a variância acumulada\n","plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', color='red', label='Variância Acumulada (%)')\n","plt.title('Análise de Variância com PCA')\n","plt.xlabel('Número de Componentes Principais')\n","plt.ylabel('Porcentagem de Variância (%)')\n","\n","plt.axhline(y=0.70, color='blue', linestyle='--', linewidth=1.5, label='70%')\n","plt.axhline(y=0.80, color='green', linestyle='--', linewidth=1.5, label='80%')\n","plt.axhline(y=0.90, color='red', linestyle='--', linewidth=1.5, label='90%')\n","\n","\n","plt.axvline(x=n_components, color='purple', linestyle='--', linewidth=1.5, label='Quantidade de Componentes')\n","\n","\n","plt.legend(loc='best')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"FZPCTS_mdNgB"},"outputs":[],"source":["# Aplicar PCA com o número de componentes selecionados\n","pca = PCA(n_components=n_components)\n","dadosPCA_reduced = pca.fit_transform(dadosPCA_scaled)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"RjOmR97YdNgC"},"outputs":[],"source":["# Criar um DataFrame com as componentes principais\n","df_pca = pd.DataFrame(dadosPCA_reduced, columns=[f'PC{i+1}' for i in range(n_components)])\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"KS4rpGZ3dNgC"},"outputs":[],"source":["# Adicionar a coluna da variável alvo\n","df_pca['CLASSE'] = classe_1.reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1726518043718,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"WN_EdYxfdNgC","outputId":"f68741df-cfde-4234-de73-17fc73ceb8cd"},"outputs":[],"source":["#Dataframe criado com as componentes principais\n","\n","df_pca.head()"]},{"cell_type":"markdown","metadata":{"id":"9Dt-191GdNgD"},"source":["O PCA selecionou 38 componentes para explicar 80% dos dados. Será criado outro dataframe que seleciona as variáveis mais correlatadas com a primeira componente principal."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"nCagJJkCdNgD"},"outputs":[],"source":["#Correlacao Selecionada, acima de:\n","\n","corre = 0.4"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"JzPmtKqgdNgE"},"outputs":[],"source":["# Ajustar o PCA aos dados e calcular as componentes principais\n","pca_components = dadosPCA_reduced.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":2780,"status":"ok","timestamp":1726518061355,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"i1Ys9J-gdNgE","outputId":"bc0e19a8-9ce0-4fd1-a7ad-5e415e90c019"},"outputs":[],"source":["# Calcular a correlação entre as variáveis originais e a primeira componente principal pela correlação de spearman\n","corr_with_PC1 = dados_sem_classe.apply(lambda x: x.corr(pd.Series(pca_components[:, 0]), method='spearman'))\n","\n","# Ordenar as variáveis por correlação absoluta com a primeira componente principal\n","corr_with_PC1_sorted = corr_with_PC1.abs().sort_values(ascending=False)\n","\n","# Criar um gráfico de barras para visualizar as correlações\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=corr_with_PC1_sorted.index, y=corr_with_PC1_sorted.values)\n","plt.xticks(rotation=90)\n","plt.xlabel('Variáveis')\n","plt.ylabel('Correlação com PC1')\n","plt.title('Correlação das Variáveis com a Primeira Componente Principal (PC1)')\n","plt.axhline(y=corre, color='red', linestyle='--', linewidth=1.5)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":2498,"status":"ok","timestamp":1726518073826,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"adOxjS87dNgE","outputId":"bcf0adcc-e909-45d2-dbad-f4c45c328767"},"outputs":[],"source":["# Calcular a correlação entre as variáveis originais e a primeira componente principal pela correlação de Pearson\n","corr2_with_PC1 = dados_sem_classe.apply(lambda x: x.corr(pd.Series(pca_components[:, 0]), method='pearson'))\n","\n","# Ordenar as variáveis por correlação absoluta com a primeira componente principal\n","corr2_with_PC1_sorted = corr2_with_PC1.abs().sort_values(ascending=False)\n","\n","# Criar um gráfico de barras para visualizar as correlações\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=corr2_with_PC1_sorted.index, y=corr_with_PC1_sorted.values)\n","plt.xticks(rotation=90)\n","plt.xlabel('Variáveis')\n","plt.ylabel('Correlação com PC1')\n","plt.title('Correlação das Variáveis com a Primeira Componente Principal (PC1)')\n","plt.axhline(y=corre, color='red', linestyle='--', linewidth=1.5)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"hAIqk-X7dNgF"},"outputs":[],"source":["# Filtrar variáveis com maior correlação\n","selected_vars = corr_with_PC1_sorted[corr_with_PC1_sorted > corre].index"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"QLQSz2RvdNgF"},"outputs":[],"source":["# Criar um novo dataframe com as variáveis selecionadas\n","df_selected = dados_sem_classe[selected_vars].copy()\n","\n","# Adicionar a coluna CLASSE ao novo dataframe\n","df_selected['CLASSE'] = classe_1.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1726518082298,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"eDy-sRAvdNgF","outputId":"f232d6af-d5ee-4384-d63f-df64903f8e58"},"outputs":[],"source":["#Novo dataframe com as variaveis mais correlatadas com a primeira componente principal\n","\n","df_selected.head()\n","#print(df_selected.shape)"]},{"cell_type":"markdown","metadata":{"id":"xKTfaV7wdNgG"},"source":["Aplicando redução pelo coeficiente de spearman"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"xnhRxDRbdNgG"},"outputs":[],"source":["# Calcular a correlação de Spearman para as variáveis\n","spearman_corr = dados_sem_classe.corr(method='spearman')"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"SwJRWzkydNgG"},"outputs":[],"source":["# Definir um limiar (threshold) para selecionar as variáveis com alta correlação\n","threshold = 0.3"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"cAXXkbFddNgH"},"outputs":[],"source":["# Selecionar as variáveis mais correlacionadas\n","correlated_vars = np.where(np.abs(spearman_corr) > threshold)\n","correlated_vars = [(spearman_corr.index[x], spearman_corr.columns[y]) for x, y in zip(*correlated_vars) if x != y]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1726518089549,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"CF1f7hpmdNgH","outputId":"3f94d8a1-8e1e-4fa0-c8fd-cac6f88dd79b"},"outputs":[],"source":["# Exibir a matriz de correlação\n","spearman_corr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":858},"executionInfo":{"elapsed":2006,"status":"ok","timestamp":1726518099106,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"0DbU5wJZdNgH","outputId":"287e1891-c9b7-4fdc-ad83-593decaa4cd0"},"outputs":[],"source":["# Plotar o heatmap da matriz de correlação\n","plt.figure(figsize=(12, 8))\n","sns.heatmap(spearman_corr, annot=False, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n","plt.title('Matriz de Correlação (Spearman)')\n","plt.show()"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"WXKJL6LcdNgI"},"outputs":[],"source":["# Remover duplicatas e manter uma cópia da variável apenas\n","selected_columns = list(set([var[0] for var in correlated_vars]))"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"2tzWfnTCdNgI"},"outputs":[],"source":["# Criar um novo dataframe com essas variáveis correlacionadas\n","df_spearman = dados_sem_classe[selected_columns].copy()\n"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"O3HjwREedNgJ"},"outputs":[],"source":["# Adicionar a coluna da variável alvo\n","df_spearman['CLASSE'] = classe_1.reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":296,"status":"ok","timestamp":1726518118451,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"ZnoLDuKudNgJ","outputId":"0d505f3b-5ef9-4c23-996a-332de3909221"},"outputs":[],"source":["# Exibir as primeiras linhas do novo DataFrame\n","df_spearman.head()"]},{"cell_type":"markdown","metadata":{"id":"g6SFe4KcdNgK"},"source":["O algoritmo não encontrou variáveis correlatadas com mais de 70%, por isso será criado um dataframe com as variáveis que possuem maior correlação com as variáveis de saída."]},{"cell_type":"code","execution_count":139,"metadata":{"id":"ciip4aBhdNgK"},"outputs":[],"source":["#Correlação a ser selecionada\n","\n","cor = 0.15"]},{"cell_type":"code","execution_count":140,"metadata":{},"outputs":[],"source":["# Converter a variável categórica 'classe_1' para valores numéricos\n","classe_1_numerica = pd.factorize(classe_1)[0]\n"]},{"cell_type":"code","execution_count":141,"metadata":{},"outputs":[],"source":["# Calcular a correlação de Spearman entre as variáveis de entrada e a variável de saída numérica\n","spearman_corr_with_target = dados_sem_classe.apply(lambda x: x.corr(pd.Series(classe_1_numerica), method='spearman'))"]},{"cell_type":"code","execution_count":142,"metadata":{},"outputs":[],"source":["# Ordenar as variáveis por ordem de correlação (absoluta) com a variável de saída\n","spearman_corr_with_target = spearman_corr_with_target.abs().sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1726518126538,"user":{"displayName":"Lucas Camaz Ferreira","userId":"04538435179332066433"},"user_tz":180},"id":"1wCQAb-QdNgK","outputId":"758dfb1d-c14d-4ced-d433-24853930da25"},"outputs":[],"source":["# Exibir a correlação de cada variável de entrada com a variável de saída\n","print(spearman_corr_with_target)\n"]},{"cell_type":"code","execution_count":144,"metadata":{},"outputs":[],"source":["# Filtrar as variáveis que têm correlação maior que 0.5 em valor absoluto\n","selected_features = spearman_corr_with_target[spearman_corr_with_target > cor].index"]},{"cell_type":"code","execution_count":145,"metadata":{},"outputs":[],"source":["# Criar um novo DataFrame apenas com essas variáveis\n","df_high_corr = dados_sem_classe[selected_features].copy()"]},{"cell_type":"code","execution_count":146,"metadata":{},"outputs":[],"source":["# Adicionar a coluna da variável alvo\n","df_high_corr['CLASSE'] = classe_1.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exibir as primeiras linhas do novo DataFrame\n","print(df_high_corr.head(10))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_high_corr"]},{"cell_type":"markdown","metadata":{"id":"qmOhXZ5mdNgL"},"source":["DataFrames criados até aqui:"]},{"cell_type":"markdown","metadata":{"id":"9ls3Lm0sdNgR"},"source":["df_pca - Componentes principais;\n","df_selected - Variaveis com maior correlacao com a Primeira Componente Principal;\n","df_spearman - Remoção das variáveis mais correlatadas;\n","df_high_corr - Variaveis de entrada com maior correlação com as variáveis de saída;"]},{"cell_type":"markdown","metadata":{"id":"JBiKtBm8dNgR"},"source":["Aplicando a seleção de Dados por k-fold"]},{"cell_type":"code","execution_count":150,"metadata":{"id":"CKK1PJVodNgR"},"outputs":[],"source":["#Selecionando o dataframe\n","\n","df_kfold = df_pca.copy()\n","#df_kfold = df_selected.copy()\n","#df_kfold = df_spearman.copy()\n","#df_kfold = df_high_corr.copy()"]},{"cell_type":"code","execution_count":151,"metadata":{"id":"jgukYMOPdNgS"},"outputs":[],"source":["# Separando as variáveis objetivo\n","X = df_kfold.drop('CLASSE', axis=1)\n","y = df_kfold['CLASSE']\n"]},{"cell_type":"code","execution_count":152,"metadata":{"id":"256ybn5CdNgS"},"outputs":[],"source":["#Definindo o número de folds\n","\n","num_folds = 7\n","sub_num_folds = 7"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"5BMnl61DdNgS"},"outputs":[],"source":["#Configurar o k-Fold Principal\n","\n","kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"FArC-O1XdNgT"},"outputs":[],"source":["#Dividir os Dados para o k-fold teste\n","\n","fold_indices = list(kf.split(X, y))"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"ZRXMGxyKdNgT"},"outputs":[],"source":["# Iterar sobre cada fold principal\n","for fold, (train_index, test_index) in enumerate(fold_indices):\n","    # Dados de treino e teste para o fold principal\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","    # Aplicar o sub-k-fold para treino e validação\n","    sub_kf = StratifiedKFold(n_splits=sub_num_folds, shuffle=True, random_state=42)\n","\n","    # Armazenar os índices dos folds secundários\n","    sub_fold_indices = list(sub_kf.split(X_train, y_train))\n","\n","    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_fold_indices):\n","        # Dados de treino e validação para o sub-k-fold\n","        X_sub_train, X_sub_val = X_train.iloc[sub_train_index], X_train.iloc[sub_val_index]\n","        y_sub_train, y_sub_val = y_train.iloc[sub_train_index], y_train.iloc[sub_val_index]\n","\n","        # Aqui você pode treinar e validar seu modelo\n","        # Exemplo: print(f'Fold {fold + 1}, Sub-Fold {sub_fold + 1}')\n"]},{"cell_type":"markdown","metadata":{},"source":["Testando disposição das Classes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from collections import Counter\n","import pandas as pd\n","\n","# Exemplo de dataframe com rótulos (alvo)\n","y = pd.Series(y)  # Supondo que seus rótulos estejam em um array ou lista chamada 'y'\n","\n","# Inicializar o StratifiedKFold\n","kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n","\n","# Iterar pelos folds principais\n","for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Contagem das classes no treino e teste\n","    train_counts = Counter(y_train)\n","    test_counts = Counter(y_test)\n","    \n","    print(f\"Fold {fold + 1}\")\n","    print(f\"Distribuição no treino: {train_counts}\")\n","    print(f\"Distribuição no teste: {test_counts}\\n\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from collections import Counter\n","import pandas as pd\n","from sklearn.model_selection import StratifiedKFold\n","\n","# Suponha que X seja um DataFrame e y seja uma Series\n","# Se X é um DataFrame e y é uma Series\n","kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n","\n","# Iterar pelos folds principais\n","for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Contagem das classes no treino e teste\n","    train_counts = Counter(y_train)\n","    test_counts = Counter(y_test)\n","    \n","    print(f\"Fold {fold + 1}\")\n","    print(f\"Distribuição no treino: {train_counts}\")\n","    print(f\"Distribuição no teste: {test_counts}\\n\")\n","\n","    # Subdividir o treino em subfolds\n","    sub_kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n","    \n","    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_kfold.split(X_train, y_train)):\n","        y_sub_train = y_train.iloc[sub_train_index]\n","        y_sub_val = y_train.iloc[sub_val_index]\n","        \n","        # Contagem das classes nos subfolds\n","        sub_train_counts = Counter(y_sub_train)\n","        sub_val_counts = Counter(y_sub_val)\n","        \n","        print(f\"  Subfold {sub_fold + 1}\")\n","        print(f\"  Distribuição no treino: {sub_train_counts}\")\n","        print(f\"  Distribuição na validação: {sub_val_counts}\\n\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rquBAk8wdNgU"},"source":["Aplicando as redes neurais no k-fold"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["# Função para criar o modelo de rede neural\n","def create_model(input_shape, num_classes):\n","    model = Sequential([\n","        Dense(12, activation='relu', input_shape=(input_shape,)),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["# Lista para armazenar as métricas de avaliação\n","validation_reports = []"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["best_model_path = 'best_model.keras'  # Local para salvar o melhor modelo\n","\n","# Configurar o callback para salvar o melhor modelo com base na métrica de validação\n","checkpoint = ModelCheckpoint(best_model_path, monitor='val_accuracy', save_best_only=True, mode='max')\n","\n","# Variável para armazenar o melhor desempenho\n","best_val_accuracy = 0\n","best_fold = None"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["# Inicializar uma lista para armazenar a precisão ponderada de cada fold\n","fold_accuracies = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Codificar os rótulos para garantir que estejam no intervalo esperado\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Aplicar k-Fold e Sub-K-Fold\n","for fold, (train_index, test_index) in enumerate(fold_indices):\n","    # Dados de treino e teste para o fold principal\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n","    \n","    # Aplicar Sub-K-Fold para treino e validação\n","    sub_fold_indices = list(sub_kf.split(X_train, y_train))\n","    \n","    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_fold_indices):\n","        # Dados de treino e validação para o sub-k-fold\n","        X_sub_train, X_sub_val = X_train.iloc[sub_train_index], X_train.iloc[sub_val_index]\n","        y_sub_train, y_sub_val = y_train[sub_train_index], y_train[sub_val_index]\n","        \n","        # Criar o modelo\n","        num_classes = len(label_encoder.classes_)\n","        model = create_model(X.shape[1], num_classes)\n","        \n","        # Treinar o modelo e salvar o histórico\n","        history = model.fit(\n","            X_sub_train, y_sub_train, \n","            epochs=100, batch_size=32, \n","            verbose=0, validation_data=(X_sub_val, y_sub_val),\n","            callbacks=[checkpoint]\n","        )\n","\n","        # Avaliar no conjunto de teste\n","        y_test_pred = model.predict(X_test)\n","        y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n","        \n","        # Calcular acurácia de teste\n","        test_accuracy = np.mean(y_test_pred_classes == y_test)\n","\n","        # Adicionar a precisão ao dicionário de precisões dos folds\n","        fold_accuracies.append({\n","            'fold': fold,\n","            'sub_fold': sub_fold,\n","            'test_accuracy': test_accuracy\n","        })\n","\n","        # Atualizar o melhor modelo se este fold for melhor\n","        if test_accuracy > best_val_accuracy:\n","            best_val_accuracy = test_accuracy\n","            best_fold = (fold, sub_fold)\n","        \n","        # # Plotar o gráfico de perda (loss) e acurácia (accuracy)\n","        # plt.figure(figsize=(12, 5))\n","\n","        # # Perda (loss)\n","        # plt.subplot(1, 2, 1)\n","        # plt.plot(history.history['loss'], label='Train Loss')\n","        # plt.plot(history.history['val_loss'], label='Validation Loss')\n","        # plt.title(f'Fold {fold + 1} Sub-Fold {sub_fold + 1} - Loss')\n","        # plt.xlabel('Epochs')\n","        # plt.ylabel('Loss')\n","        # plt.legend()\n","\n","        # # Acurácia (accuracy)\n","        # plt.subplot(1, 2, 2)\n","        # plt.plot(history.history['accuracy'], label='Train Accuracy')\n","        # plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","        # plt.title(f'Fold {fold + 1} Sub-Fold {sub_fold + 1} - Accuracy')\n","        # plt.xlabel('Epochs')\n","        # plt.ylabel('Accuracy')\n","        # plt.legend()\n","\n","        # # Mostrar o gráfico\n","        # plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exibir precisões ponderadas de cada fold\n","for accuracy in fold_accuracies:\n","    print(f\"Fold {accuracy['fold']}, Sub-Fold {accuracy['sub_fold']}: Acurácia de Teste = {accuracy['test_accuracy']:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Carregar o melhor modelo\n","best_model = load_model(best_model_path)\n","\n","# Fazer previsões no conjunto de teste final\n","y_test_pred = best_model.predict(X_test)\n","y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n","\n","# Gerar a matriz de confusão\n","cm = confusion_matrix(y_test, y_test_pred_classes)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot()\n","\n","# Exibir a acurácia final do melhor modelo\n","print(f\"Melhor acurácia no fold {best_fold[0]+1}, sub-fold {best_fold[1]+1}: {best_val_accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calcular a matriz de confusão original\n","conf_matrix = confusion_matrix(y_test, y_test_pred_classes)\n","\n","# Frequência das classes no conjunto de dados\n","class_counts = np.bincount(y_test)  # Conta o número de ocorrências de cada classe\n","class_weights = 1.0 / class_counts  # Calcula o peso de cada classe\n","\n","# Matriz de confusão ponderada\n","weighted_conf_matrix = conf_matrix * class_weights[:, np.newaxis]\n","\n","# Exibir a matriz de confusão ponderada\n","print(\"Matriz de Confusão Ponderada:\")\n","print(weighted_conf_matrix)\n","\n","# Calcular a precisão de cada classe\n","precisions = []\n","for i in range(weighted_conf_matrix.shape[0]):\n","    true_positives = weighted_conf_matrix[i, i]  # Verdadeiros Positivos\n","    false_positives = sum(weighted_conf_matrix[:, i]) - true_positives  # Falsos Positivos\n","    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n","    precisions.append(precision)\n","\n","# Exibir a precisão de cada classe\n","for idx, precision in enumerate(precisions):\n","    print(f'Precisão da Classe {idx}: {precision:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, precision_score\n","\n","# Armazenar as precisões por classe para cada sub-fold\n","sub_fold_precisions = []\n","\n","# Exibir a precisão de cada classe\n","for fold, (train_index, test_index) in enumerate(fold_indices):\n","    # Dados de treino e teste para o fold principal\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n","    \n","    # Aplicar Sub-K-Fold para treino e validação\n","    sub_fold_indices = list(sub_kf.split(X_train, y_train))\n","    \n","    for sub_fold, (sub_train_index, sub_val_index) in enumerate(sub_fold_indices):\n","        # Dados de treino e validação para o sub-k-fold\n","        X_sub_train, X_sub_val = X_train.iloc[sub_train_index], X_train.iloc[sub_val_index]\n","        y_sub_train, y_sub_val = y_train[sub_train_index], y_train[sub_val_index]\n","        \n","        # Criar o modelo\n","        num_classes = len(label_encoder.classes_)\n","        model = create_model(X.shape[1], num_classes)\n","        \n","        # Treinar o modelo e salvar o histórico\n","        history = model.fit(\n","            X_sub_train, y_sub_train, \n","            epochs=100, batch_size=32, \n","            verbose=0, validation_data=(X_sub_val, y_sub_val),\n","            callbacks=[checkpoint]\n","        )\n","\n","        # Avaliar no conjunto de teste\n","        y_test_pred = model.predict(X_test)\n","        y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n","        \n","        # Calcular a matriz de confusão\n","        cm = confusion_matrix(y_test, y_test_pred_classes, labels=np.arange(num_classes))\n","        \n","        # Calcular a precisão de cada classe\n","        class_precisions = precision_score(y_test, y_test_pred_classes, average=None)\n","        \n","        # Armazenar a precisão de cada classe para o sub-fold\n","        sub_fold_precisions.append({\n","            'fold': fold,\n","            'sub_fold': sub_fold,\n","            'precisions': class_precisions\n","        })"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exibir precisões de cada classe para cada sub-fold\n","for sub_fold_precision in sub_fold_precisions:\n","    print(f\"Fold {sub_fold_precision['fold']}, Sub-Fold {sub_fold_precision['sub_fold']}:\")\n","    for i, precision in enumerate(sub_fold_precision['precisions']):\n","        print(f\"  Precisão da Classe {i}: {precision:.4f}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":0}
